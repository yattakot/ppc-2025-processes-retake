# Отчет

## Подсчёт количества различающихся символов в двух строках

Студент: Куликов Денис
Группа: 3823Б1ПР1
Технологии: SEQ, MPI
Вариант: 27

### 1. Введение

Задача сравнения двух строк и подсчёта количества несовпадающих символов является базовой задачей обработки данных.
Несмотря на простоту, она хорошо демонстрирует принципы параллельных вычислений,
так как операции сравнения символов  зависят друг от друга.
 данной работы является реализация последовательного и параллельного алгоритмов
 подсчёта количества различающихся символов
 с использованием MPI, а также проверка их корректности и анализ производительности.

### 2. Постановка задачи

Задано:
Две строки s1 и s2, состоящие из однобайтовых символов

Требуется:
Определить количество позиций, на которых символы строк различаются.
Если длины строк различны, все «лишние» символы более длинной строки считаются несовпадающими.

Требования к решению:

Алгоритм должен корректно работать для строк любой длины, включая пустые.
Учитывается регистр символов.
Последовательная и параллельная версии должны выдавать одинаковый результат.
Параллельная реализация должна использовать MPI.

### 3. Последовательный алгоритм

### 3.1. Описание алгоритма

Последовательная версия алгоритма выполняет прямое сравнение строк:

Определяются минимальная и максимальная длины строк.
Выполняется поэлементное сравнение символов в диапазоне общей длины.
Подсчитывается количество несовпадающих символов.
К результату добавляется разница длин строк.

### 3.2. Вычислительная сложность

Временная сложность алгоритма равна

O(min(n,m)),

где n и m — длины входных строк.

### 3.3. Особенности реализации

Используется обычный цикл без дополнительных структур данных.
Реализация не требует дополнительной памяти, кроме входных строк.
Подходит для небольших и средних размеров данных.

### 4. Параллельный алгоритм (MPI)

### 4.1. Общая идея распараллеливания

Параллельная версия алгоритма распределяет сравнение символов общей части строк между процессами.
Каждый процесс обрабатывает свой непрерывный диапазон индексов и подсчитывает локальное количество различий.
После этого локальные результаты суммируются.

### 4.2. Организация вычислений

Все процессы получают размеры строк с помощью MPI_Bcast.
Строки распределяются по кускам с помощью MPI_Scatterv, каждый процесс получает только свой диапазон символов.
Диапазон общей части строк делится между процессами с учётом остатка.
Каждый процесс сравнивает символы в своём диапазоне.
Локальные результаты объединяются с помощью MPI_Allreduce.
К итоговому результату добавляется разница длин строк.

### 4.3. Распределение диапазонов

Для балансировки нагрузки используется следующая схема:

Общая длина min_len делится на количество процессов.
Первые rem процессов получают на один элемент больше.
Диапазон [begin, end) вычисляется индивидуально для каждого процесса.
Это обеспечивает равномерное распределение работы без перекрытий.

### 5. Детали реализации

### 5.1. Структура проекта

kulikov_d_coun_number_char/
├── common/
│   └── include/common.hpp
├── mpi/
│   ├── include/ops_mpi.hpp
│   └── src/ops_mpi.cpp
├── seq/
│   ├── include/ops_seq.hpp
│   └── src/ops_seq.cpp
├── tests/
│   ├── functional/
│   │   └── main.cpp
│   └── performance/
│       └── main.cpp

### 5.2. Основные классы

KulikovDiffCountNumberCharSEQ — последовательная версия алгоритма.
KulikovDiffCountNumberCharMPI — параллельная версия с использованием MPI.
Каждый класс реализует стандартные методы:
ValidationImpl()
PreProcessingImpl()
RunImpl()
PostProcessingImpl()

### 6. Обработка граничных случаев

В реализации учтены следующие ситуации:

Пустые строки — корректно возвращается 0 или длина непустой строки.
Разная длина строк — лишние символы считаются несовпадающими.
Пробелы и управляющие символы — обрабатываются как обычные символы.
Регистр символов — 'a' и 'A' считаются разными
ASCII-символы — алгоритм работает с однобайтовыми символами.

### 7. Тестирование

### 7.1. Функциональные тесты

Функциональное тестирование выполнено с использованием Google Test.

Тесты проверяют корректность работы алгоритма на различных наборах данных:
    пустые строки;
    идентичные строки;
    строки с одним отличием;
    строки разной длины;
    строки со спецсимволами;
    длинные строки.

Обе реализации (SEQ и MPI) проходят все функциональные тесты и выдают одинаковые результаты.

### 7.2. Тесты производительности

Для оценки производительности используются строки длиной до 200 миллионов символов.
Различия в строках создаются с фиксированным шагом, что позволяет заранее вычислить ожидаемый результат.
Измеряются два режима:
полное время выполнения задачи;
время работы метода RunImpl.

### 8. Анализ результатов

Параллельная MPI-версия алгоритма была протестирована на нескольких процессах, а последовательная версия — на одном процессе.

В ходе экспериментов были получены следующие результаты (размер строк: 200 млн символов):

1. Четыре процесса MPI

| Реализация | Режим          | Время выполнения (с) |
|------------|----------------|----------------------|
| **SEQ**    | pipeline       | 0.129                |
| **SEQ**    | task_run       | 0.135                |
| **MPI**    | pipeline       | 0.220                |
| **MPI**    | task_run       | 0.208                |

2. Два процесса MPI

| Реализация | Режим          | Время выполнения (с) |
|------------|----------------|----------------------|
| **SEQ**    | pipeline       | 0.129                |
| **SEQ**    | task_run       | 0.129                |
| **MPI**    | pipeline       | 0.243                |
| **MPI**    | task_run       | 0.242                |

3. Один процесс MPI

| Реализация | Режим          | Время выполнения (с) |
|------------|----------------|----------------------|
| **SEQ**    | pipeline       | 0.124                |
| **SEQ**    | task_run       | 0.124                |
| **MPI**    | pipeline       | 0.309                |
| **MPI**    | task_run       | 0.302                |

Наблюдения:

1. Последовательная версия демонстрирует стабильное и предсказуемое время выполнения (~0.13 с).
2. Параллельная версия (MPI) оказалась медленнее SEQ в 1.6–1.7 раза, несмотря на использование нескольких процессов.
3. Причина замедления:
    Накладные расходы на передачу данных (широковещательная рассылка строк через MPI_Bcast) превышают выигрыш от распараллеливания.
    Задача имеет крайне низкую вычислительную плотность: операция s1[i] != s2[i] выполняется за несколько тактов CPU,
    в то время как передача 200 МБ данных через MPI занимает значительно больше времени.
4. Scatterv снижает накладные расходы по сравнению с Bcast, но для такой лёгкой операции это всё равно не дает выигрыш

### 9. Выводы

В ходе работы были получены следующие результаты:
Реализованы последовательная и параллельная версии алгоритма подсчёта различающихся символов.
Подтверждена корректность работы алгоритмов на широком наборе тестов.
Показано, что для задач с простыми операциями и интенсивным доступом к памяти
MPI-параллелизация не всегда даёт выигрыш по времени.
Реализация демонстрирует основные принципы работы с MPI: широковещание, редукцию и распределение нагрузки.

### 10. Заключение

Данная работа наглядно показывает, что эффективность параллельных алгоритмов зависит не только от возможности распараллеливания,
но и от соотношения вычислений и коммуникаций.
Для более ресурсоёмких задач аналогичный подход может дать значительный прирост производительности.
